# number of nginx workers (just asynchronously forwarding)
# only 1 should be enough (2 recommended until we investigate more)
worker_processes 2;

# docker points the path to stderr
error_log /var/log/nginx/error.log;

events {
    # number of opened connections per worker (both sides)
    # default limit is 1024 on OS
    # real value 2 x 16 x coog workers number
    # since we want to buffer and we don't have a strategy for worker_processes
    # => set to max
    worker_connections 1024;

    # accept immediately as many connection as it can
    multi_accept on;
}

http {
    # docker points the path to stdout
    include /etc/nginx/mime.types;

    log_format coog '$time_iso8601 $remote_addr $request $request_time $request_length $bytes_sent $status $upstream_addr';
    access_log /var/log/nginx/access.log coog;

    # timeout in seconds (nginx <-> client)
    # depends on heaviest transactions
    send_timeout 600;

    # timeout in seconds (nginx <-> backend)
    # depends on heaviest transactions
    proxy_send_timeout 600;
    proxy_read_timeout 600;

    # avoid waiting to have big pacquets (to avoid protocols overhead)
    # https://t37.net/optimisations-nginx-bien-comprendre-sendfile-tcp-nodelay-et-tcp-nopush.html
    tcp_nodelay on;

    upstream coog_workers {
        # least_conn is the load balacing method that select a server with
        # the less active(s) connection(s) for the next request.
        least_conn;

        # coog workers (add more from remote hosts)
        server coog:7999;
    }

    server {
        # main entry point url (default on nginx docker image)
        listen 80;
        index index.html;
        location / {
            root /coog/sao;
            if ($request_method = POST) {
                proxy_pass http://coog_workers;
            }
        }
        location /bench {
            alias /coog/coog-bench;
        }
    }
}
