# number of nginx workers (just asynchronously forwarding)
# only 1 should be enough (2 recommended until we investigate more)
worker_processes 2;

# docker points the path to stderr
error_log /var/log/nginx/error.log;

events {
    # number of opened connections per worker (both sides)
    # default limit is 1024 on OS
    # real value 2 x 16 x coog workers number
    # since we want to buffer and we don't have a strategy for worker_processes
    # => set to max
    worker_connections 1024;

    # accept immediately as many connection as it can
    multi_accept on;
}

http {
    # docker points the path to stdout
    include /etc/nginx/mime.types;

    log_format coog '$time_iso8601 $remote_addr $upstream_addr $status $request_length $bytes_sent $request_time $upstream_http_rpc_method $gzip_ratio';
    access_log /var/log/nginx/access.log coog;

    # timeout in seconds (nginx <-> client)
    # depends on heaviest transactions
    send_timeout 600;

    # timeout in seconds (nginx <-> backend)
    # depends on heaviest transactions
    proxy_send_timeout 600;
    proxy_read_timeout 600;

    upstream coog_workers {
        # least_conn is the load balacing method that select a server with
        # the less active(s) connection(s) for the next request.
        least_conn;

        # coog workers (add more from remote hosts)
        server coog:8000;
    }

    server {
        # main entry point url (default on nginx docker image)
        listen 80;
        index index.html;
        location / {
            gzip on;
            gzip_proxied any;
            gzip_types application/json;
            gzip_min_length 1400;
            root /workspace/sao;
            if ($request_method = POST) {
                proxy_pass http://coog_workers;
            }
        }
        location /bench {
            alias /workspace/coog-bench/public;
        }
    }
}
